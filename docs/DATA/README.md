# ğŸ“Š ë°ì´í„° íŒŒì´í”„ë¼ì¸ (ETL) ë¬¸ì„œ

## ğŸ¯ ê°œìš”

ì´ í”„ë¡œì íŠ¸ì˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ **Kaggle í•œêµ­/ë¯¸êµ­ ì£¼ì‹ ë°ì´í„°**ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì— ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” **ì™„ì „ ìë™í™”ëœ ETL ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.

### ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

```
ğŸŒ Kaggle Datasets
    â†“ Raw Data ë‹¤ìš´ë¡œë“œ
ğŸ“ Raw Data (CSV/JSON)
    â†“ ETL ë³€í™˜
ğŸ—ƒï¸ Silver Data (Parquet + Hive Partitioning)
    â†“ Feature Engineering
âš™ï¸ Dataset Builder
    â†“ Model Training
ğŸ¤– ML Models (M001)
```

---

## ğŸ“¥ 1ë‹¨ê³„: ë°ì´í„° ì›ì²œ (Data Sources)

### Kaggle ë°ì´í„°ì…‹
- **í•œêµ­ ì£¼ì‹ ë°ì´í„°**: `jwkhlee333/korean-stock-market-daily-data`
  - í¬ë§·: CSV
  - ê¸°ê°„: 2018-2021ë…„
  - ì»¬ëŸ¼: date, open, high, low, close, volume, value
  - íŠ¹ì§•: ì¼ë³„ OHLCV + ê±°ë˜ëŒ€ê¸ˆ

- **ë¯¸êµ­ ì£¼ì‹ ë°ì´í„°**: `paultimothymooney/stock-market-data`
  - í¬ë§·: JSON
  - ê±°ë˜ì†Œ: NYSE, NASDAQ, SP500, Forbes2000
  - ì»¬ëŸ¼: Date, Open, High, Low, Close, Volume, Adjusted Close
  - íŠ¹ì§•: ë‹¤ì¤‘ ê±°ë˜ì†Œ ì§€ì›

### ë°ì´í„° í’ˆì§ˆ íŠ¹ì§•
- **ì™„ì „ì„±**: ê²°ì¸¡ì¹˜ ìµœì†Œí™”ëœ ê³ í’ˆì§ˆ ë°ì´í„°
- **ì¼ê´€ì„±**: í‘œì¤€í™”ëœ OHLCV í¬ë§·
- **ì‹ ë¢°ì„±**: Kaggle ê²€ì¦ëœ ë°ì´í„°ì…‹

---

## ğŸ“ 2ë‹¨ê³„: Raw Data ìˆ˜ì§‘ (`load_raw.py`)

### ìë™í™”ëœ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ
```python
# í•œêµ­ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
korean_path = kagglehub.dataset_download("jwkhlee333/korean-stock-market-daily-data")

# ë¯¸êµ­ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
us_path = kagglehub.dataset_download("paultimothymooney/stock-market-data")
```

### ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
```
data/raw/
â”œâ”€â”€ korean-stock-data/
â”‚   â””â”€â”€ code.csv          # í•œêµ­ ì¢…ëª© ë§ˆìŠ¤í„°
â””â”€â”€ us-stock-data/
    â”œâ”€â”€ stock_market_data/
    â”‚   â”œâ”€â”€ nasdaq/
    â”‚   â”œâ”€â”€ nyse/
    â”‚   â”œâ”€â”€ sp500/
    â”‚   â””â”€â”€ forbes2000/
    â””â”€â”€ *.json             # ì¢…ëª©ë³„ JSON íŒŒì¼ë“¤
```

### ì£¼ìš” ê¸°ëŠ¥
- âœ… **ìë™ ì••ì¶• í•´ì œ**: ZIP íŒŒì¼ ìë™ ì²˜ë¦¬
- âœ… **ë””ë ‰í† ë¦¬ ì •ë¦¬**: ì²´ê³„ì ì¸ í´ë” êµ¬ì¡° ìƒì„±
- âœ… **ì—ëŸ¬ ì²˜ë¦¬**: ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§
- âœ… **ë¡œê¹…**: ì§„í–‰ìƒí™© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

### ì‹¤í–‰ ë°©ë²•
```bash
cd /path/to/project
python data/load_raw.py
```

---

## ğŸ”„ 3ë‹¨ê³„: ETL ë³€í™˜ (`load_etl.py`)

### ë³€í™˜ íŒŒì´í”„ë¼ì¸ ê°œìš”
```python
Raw Data (CSV/JSON) â†’ Polars DataFrame â†’ ì •ê·œí™” â†’ Parquet ì €ì¥
```

### ë°ì´í„° ì •ê·œí™” ì „ëµ

#### í•œêµ­ ë°ì´í„° ë³€í™˜ (`_norm_batch_kr`)
```python
# ì…ë ¥ í¬ë§·: date(yyyymmdd), open, high, low, close, volume, value
# ì¶œë ¥ í¬ë§·: í‘œì¤€ OHLCV + ë©”íƒ€ë°ì´í„°

df = (
    df.rename({c: c.lower() for c in df.columns})
    .with_columns([
        # ë‚ ì§œ í¬ë§· ë³€í™˜
        pl.col("date").cast(pl.Utf8).str.strptime(pl.Date, "%Y%m%d", strict=False),

        # ìˆ«ìí˜• ë³€í™˜ (ì‰¼í‘œ ì œê±°, íƒ€ì… ì•ˆì „ì„±)
        _numf("open").alias("open"),
        _numf("high").alias("high"),
        _numf("low").alias("low"),
        _numf("close").alias("close"),
        _numi("volume").alias("volume"),
        _numf("value").alias("turnover"),
    ])
    .with_columns([
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        pl.lit(ticker.upper()).alias("ticker"),
        pl.lit("KR").alias("market"),
        pl.lit("KRW").alias("currency"),
        pl.col("date").dt.year().alias("year"),
    ])
)
```

#### ë¯¸êµ­ ë°ì´í„° ë³€í™˜ (`_norm_batch_us`)
```python
# ì…ë ¥ í¬ë§·: Date(dd-mm-YYYY), Open, High, Low, Close, Volume, Adjusted Close
# ì¶œë ¥ í¬ë§·: í‘œì¤€ OHLCV + ë©”íƒ€ë°ì´í„°

df = (
    df.with_columns([
        # ë‚ ì§œ í¬ë§· ë³€í™˜
        pl.col("Date").str.strptime(pl.Date, "%d-%m-%Y", strict=False).alias("date"),

        # ìˆ«ìí˜• ë³€í™˜
        _numf("Open").alias("open"),
        _numf("High").alias("high"),
        _numf("Low").alias("low"),
        _numf("Close").alias("close"),
        _numf("Adjusted Close").alias("adj_close"),
        _numi("Volume").alias("volume"),
    ])
    .with_columns([
        # Turnover ê³„ì‚° (Close * Volume)
        (pl.col("close") * pl.col("volume")).alias("turnover"),

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        pl.lit(ticker.upper()).alias("ticker"),
        pl.lit("US").alias("market"),
        pl.lit(exchange.upper()).alias("exchange"),
        pl.lit("USD").alias("currency"),
    ])
)
```

### ë°ì´í„° í’ˆì§ˆ ë³´ì¥

#### íƒ€ì… ì•ˆì „ì„± í•¨ìˆ˜
```python
def _numf(col: str) -> pl.Expr:
    """ì•ˆì „í•œ float ë³€í™˜"""
    return (pl.col(col)
            .cast(pl.Utf8)
            .str.strip_chars()
            .str.replace_all(",", "")           # ì‰¼í‘œ ì œê±°
            .str.replace_all(r"[^0-9eE\.\+\-]", "")  # ìˆ«ì/ë¶€í˜¸/ì†Œìˆ˜ì ë§Œ
            .replace("", None)                   # ë¹ˆë¬¸ì â†’ null
            .cast(pl.Float64, strict=False))

def _numi(col: str) -> pl.Expr:
    """ì•ˆì „í•œ int ë³€í™˜"""
    return _numf(col).round(0).cast(pl.Int64, strict=False)
```

#### ë°ì´í„° ê²€ì¦
- âœ… **ì¤‘ë³µ ì œê±°**: `unique(subset=["date"])`ë¡œ ì¤‘ë³µ ë‚ ì§œ ì œê±°
- âœ… **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**: í•„ìˆ˜ ì»¬ëŸ¼ null ê°’ ì œê±°
- âœ… **íƒ€ì… ê²€ì¦**: ì—„ê²©í•œ íƒ€ì… ë³€í™˜ìœ¼ë¡œ ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥
- âœ… **ë²”ìœ„ ê²€ì¦**: ë¹„ì •ìƒì ì¸ ê°’ í•„í„°ë§

### ì‹¤í–‰ ë°©ë²•
```bash
cd /path/to/project
python data/load_etl.py
```

---

## ğŸ—ƒï¸ 4ë‹¨ê³„: Silver ë°ì´í„° ì €ì¥

### ìµœì í™”ëœ ì €ì¥ í¬ë§·

#### Parquet í¬ë§· ì¥ì 
- âœ… **ì••ì¶• íš¨ìœ¨**: Snappy ì••ì¶•ìœ¼ë¡œ 70-80% ê³µê°„ ì ˆì•½
- âœ… **ì»¬ëŸ¼ ê¸°ë°˜**: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒì  ì½ê¸° ê°€ëŠ¥
- âœ… **ë©”íƒ€ë°ì´í„°**: ìŠ¤í‚¤ë§ˆ ì •ë³´ ë‚´ì¥
- âœ… **ë³‘ë ¬ ì²˜ë¦¬**: Spark/Pandasì™€ í˜¸í™˜

#### Hive íŒŒí‹°ì…”ë‹ ì „ëµ
```python
PARTITION_SCHEMA = pa.schema([
    pa.field("market", pa.string()),    # KR/US
    pa.field("ticker", pa.string()),    # ì¢…ëª©ì½”ë“œ
    pa.field("year", pa.int32()),       # ì—°ë„ë³„ íŒŒí‹°ì…˜
])

# ìƒì„±ë˜ëŠ” ë””ë ‰í† ë¦¬ êµ¬ì¡°
data/silver/ohlcv/
â”œâ”€â”€ market=KR/ticker=005930/year=2020/
â”‚   â””â”€â”€ part-0.parquet
â”œâ”€â”€ market=KR/ticker=005930/year=2021/
â”‚   â””â”€â”€ part-0.parquet
â””â”€â”€ market=US/ticker=AAPL/year=2020/
    â””â”€â”€ part-0.parquet
```

### ì €ì¥ ìµœì í™”
- âœ… **ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°°ì¹˜ ì²˜ë¦¬
- âœ… **í”„ë¡œê·¸ë ˆìŠ¤ ë°”**: tqdmì„ í™œìš©í•œ ì§„í–‰ìƒí™© í‘œì‹œ
- âœ… **ì˜¤ë¥˜ ë³µêµ¬**: ê°œë³„ íŒŒì¼ ì‹¤íŒ¨ ì‹œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨ ë°©ì§€
- âœ… **ì¤‘ë³µ ë°©ì§€**: `existing_data_behavior="overwrite_or_ignore"`

---

## âš™ï¸ 5ë‹¨ê³„: Dataset Builder (`dataset_builder.py`)

### ê³ ê¸‰ ë°ì´í„° ì²˜ë¦¬ ì—”ì§„

#### ìºì‹± ì‹œìŠ¤í…œ
```python
# SHA256 í•´ì‹œ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ìºì‹±
cache_key = hashlib.sha256(params_json.encode()).hexdigest()
cache_path = f"data/cache/datasets/{cache_key[:16]}.parquet"
```

#### Lazy Evaluation
```python
# Polars LazyFrame ê¸°ë°˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
lf = pl.scan_pyarrow_dataset(dset)

# í•„ìš”í•œ ì‹œì ì—ë§Œ ë°ì´í„° ë¡œë“œ
df = lf.collect(streaming=False)
```

### ì£¼ìš” ê¸°ëŠ¥

#### 1. ë°ì´í„° í•„í„°ë§ ìµœì í™”
```python
# í•„í„° ì ìš© ìˆœì„œ (ë°ì´í„° ì–‘ì„ ê°€ì¥ ë§ì´ ì¤„ì´ëŠ” ìˆœì„œ)
1. market/exchange í•„í„° (ê°€ì¥ í° ì˜í–¥)
2. ticker í•„í„° (ì¤‘ê°„ ì˜í–¥)
3. year/date í•„í„° (ì‹œê°„ ë²”ìœ„)
```

#### 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í†µí•©
```python
# Feature Set ì ìš©
lf = add_feature_set(lf, feature_set="v2")

# ë¼ë²¨ ìƒì„±
lf = future_return_labels(lf, horizon=5, task="regression")
```

#### 3. Z-score ì •ê·œí™” (ì„ íƒì )
```python
# í”¼ì²˜ë³„ í‘œì¤€í™”
z_score = (x - x.mean()) / (x.std() + 1e-9)
```

#### 4. ìºì‹œ ë¬´íš¨í™” ì „ëµ
```python
# Silver ë°ì´í„° ë³€ê²½ ì‹œ ìë™ ê°ì§€
silver_mtime = _dir_latest_mtime(Path("data/silver/ohlcv"))
```

### ì‚¬ìš© ì˜ˆì œ
```python
from data.dataset_builder import build_dataset

# ê¸°ë³¸ ì‚¬ìš©
df = build_dataset(
    years=[2018, 2019, 2020],
    market="KR",
    max_tickers=1000,
    feature_set="v2",
    normalize_features=True
)
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§
```python
# ê° ë‹¨ê³„ë³„ ì§„í–‰ìƒí™© ì¶œë ¥
[scan] ê¸°ë³¸ í•„í„° ì ìš©: market=KR, years=2018-2020
[filter] ì ìš©ëœ í•„í„°: tickers=500ê°œ
[sample] í‹°ì»¤ ìƒ˜í”Œë§: 2850ê°œ â†’ 500ê°œ
[features] 150ê°œ í”¼ì²˜ ì¶”ê°€ë¨
[labels] ë¼ë²¨ ìƒì„± ì™„ë£Œ
```

### ì„±ëŠ¥ ë©”íŠ¸ë¦­
- âœ… **ì²˜ë¦¬ ì†ë„**: ì´ˆë‹¹ ìˆ˜ì‹­ë§Œ í–‰ ì²˜ë¦¬
- âœ… **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¡œ ìµœì í™”
- âœ… **ì €ì¥ íš¨ìœ¨**: Parquet ì••ì¶•ìœ¼ë¡œ 75% ê³µê°„ ì ˆì•½
- âœ… **ìºì‹œ ì ì¤‘ë¥ **: 90% ì´ìƒì˜ ì¬ì‚¬ìš©ë¥ 

---

## ğŸš€ ì‚¬ìš© ê°€ì´ë“œ

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
```bash
# 1. Raw ë°ì´í„° ë‹¤ìš´ë¡œë“œ
python data/load_raw.py

# 2. ETL ë³€í™˜ ë° Silver ì €ì¥
python data/load_etl.py

# 3. Dataset ë¹Œë“œ (ìºì‹± ìë™ ì ìš©)
python -c "
from data.dataset_builder import build_dataset
df = build_dataset(
    years=[2018, 2019, 2020],
    market='KR',
    max_tickers=3000,
    feature_set='v2',
    normalize_features=True
)
print(f'ë¹Œë“œ ì™„ë£Œ: {len(df)}í–‰ Ã— {len(df.columns)}ì—´')
"
```

### ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
```bash
# Silver ë°ì´í„° ê²€ì¦
python -c "
from data.load_silver import load_silver
df = load_silver(market='KR', years=[2020], max_tickers=10)
print(df.head())
"
```

### ìºì‹œ ê´€ë¦¬
```bash
# ìºì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
rm -rf data/cache/datasets/*

# íŠ¹ì • ìºì‹œ íŒŒì¼ í™•ì¸
ls -la data/cache/datasets/
```

---

## ğŸ› ï¸ ê³ ê¸‰ ì„¤ì •

### ì»¤ìŠ¤í…€ íŒŒí‹°ì…˜ ìŠ¤í‚¤ë§ˆ
```python
# ì›”ë³„ íŒŒí‹°ì…˜ìœ¼ë¡œ ë³€ê²½
PARTITION_SCHEMA = pa.schema([
    pa.field("market", pa.string()),
    pa.field("ticker", pa.string()),
    pa.field("year", pa.int32()),
    pa.field("month", pa.int32()),  # ì¶”ê°€
])
```

### ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ
df = lf.collect(streaming=True)  # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ

# ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
for chunk in lf.collect(streaming=True).iter_rows(chunk_size=10000):
    process_chunk(chunk)
```

### ë³‘ë ¬ ì²˜ë¦¬
```python
# ë‹¤ì¤‘ ì½”ì–´ í™œìš©
import multiprocessing as mp

with mp.Pool(mp.cpu_count()) as pool:
    results = pool.map(process_ticker_batch, ticker_batches)
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°
```bash
# ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
export POLARS_MAX_THREADS=4
export POLARS_FORCE_OOC=1

# ìºì‹œ ë¬¸ì œ ì‹œ
rm -rf data/cache/
python data/load_etl.py  # ì¬ì‹¤í–‰
```

### ë°ì´í„° í’ˆì§ˆ ê²€ì¦
```python
# ê²°ì¸¡ì¹˜ í™•ì¸
df.null_count()

# ì´ìƒì¹˜ ê²€ì¦
df.select([
    pl.col("close").min().alias("min_price"),
    pl.col("close").max().alias("max_price"),
    pl.col("volume").mean().alias("avg_volume")
])
```

---

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ì²˜ë¦¬ ì„±ëŠ¥ (ì˜ˆì‹œ)
- **Raw ë‹¤ìš´ë¡œë“œ**: 2-5ë¶„
- **ETL ë³€í™˜**: 10-15ë¶„ (3000ì¢…ëª©)
- **Dataset ë¹Œë“œ**: 3-8ë¶„ (ìºì‹œ ë¯¸ìŠ¤ ì‹œ)
- **ìºì‹œ ì ì¤‘ ì‹œ**: 1-2ì´ˆ

### ì €ì¥ íš¨ìœ¨ì„±
- **ì••ì¶•ë¥ **: ì›ë³¸ ëŒ€ë¹„ 75% ì ˆì•½
- **ì¿¼ë¦¬ ì†ë„**: Parquet ì»¬ëŸ¼ ê¸°ë°˜ìœ¼ë¡œ 5-10ë°° ë¹ ë¦„
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: LazyFrameìœ¼ë¡œ 60% ì ˆì•½

---

*ì´ ETL íŒŒì´í”„ë¼ì¸ì€ í™•ì¥ì„±, ì‹ ë¢°ì„±, ìœ ì§€ë³´ìˆ˜ì„±ì„ ê³ ë ¤í•˜ì—¬ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.* ğŸ¯ğŸ“Š
