# models/M001_DirectionClassifier.py
"""
ë°©í–¥ ë¶„ë¥˜ ëª¨ë¸ (LightGBM ê¸°ë°˜ ì´ì§„ ë¶„ë¥˜ê¸°)

ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œë¥¼ ê³ ë ¤í•˜ì—¬ ì„ ë³„ëœ featureë“¤ì„ ì‚¬ìš©í•˜ì—¬
ìƒìŠ¹/í•˜ë½ ë°©í–¥ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
"""

import os
import pickle
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

import polars as pl
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score,
    accuracy_score, precision_score, recall_score, f1_score
)
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns

from data.dataset_builder import build_dataset

# === Feature Selection (ë‹¤ì¤‘ê³µì„ ì„± ê³ ë ¤) ===
SELECTED_FEATURES = [
    # RSI ê·¸ë£¹ (rsi14 ì„ íƒ - ê°€ì¥ ì•ˆì •ì )
    'rsi14',

    # ì´ë™í‰ê·  ê·¸ë£¹ (ema20, sma50 ì„ íƒ - ì¥ë‹¨ê¸° ê· í˜•)
    'ema20',
    'sma50',

    # ìˆ˜ìµë¥  ê·¸ë£¹ (roc10 ì„ íƒ - ì ì ˆí•œ ê¸°ê°„)
    'roc10',

    # ìŠ¤í† ìºìŠ¤í‹± ê·¸ë£¹ (stochd14 ì„ íƒ - smoothed ë²„ì „)
    'stochd14',

    # ê±°ë˜ëŸ‰ ê·¸ë£¹ (vol_z20 ì„ íƒ - í‘œì¤€í™”ëœ ë³€ë™ì„±)
    'vol_z20',

    # ë³€ë™ì„± ê·¸ë£¹ (parkinson20 ì„ íƒ - Parkinson ë³€ë™ì„±)
    'parkinson20',

    # MACD ê·¸ë£¹ (macd_hist ì„ íƒ - íˆìŠ¤í† ê·¸ë¨)
    'macd_hist',

    # ATR ê·¸ë£¹ (atr14 ì„ íƒ - ì•ˆì •ì )
    'atr14',

    # VWAP ê·¸ë£¹ (vwap20 ì„ íƒ - ë” ê¸´ ê¸°ê°„)
    'vwap20',

    # ê°€ê²© êµ¬ì¡° (pos_in_don20 ì„ íƒ - Donchian position)
    'pos_in_don20',

    # OBV ê·¸ë£¹ (obv ì„ íƒ - On Balance Volume)
    'obv',

    # MFI ê·¸ë£¹ (mfi14 ì„ íƒ)
    'mfi14',

    # CCI ê·¸ë£¹ (cci20 ì„ íƒ)
    'cci20',

    # Williams %R (willr14 ì„ íƒ)
    'willr14'
]

class DirectionClassifierLGBM:
    """
    LightGBM ê¸°ë°˜ ë°©í–¥ ë¶„ë¥˜ ëª¨ë¸

    Features: ë‹¤ì¤‘ê³µì„ ì„± ê³ ë ¤í•˜ì—¬ ì„ ë³„ëœ 16ê°œ feature
    Target: +1 (ìƒìŠ¹), -1 (í•˜ë½) ì´ì§„ ë¶„ë¥˜
    """

    def __init__(self,
                 model_params: Optional[Dict] = None,
                 feature_list: Optional[List[str]] = None):
        """
        Args:
            model_params: LightGBM ëª¨ë¸ íŒŒë¼ë¯¸í„°
            feature_list: ì‚¬ìš©í•  feature ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: SELECTED_FEATURES)
        """
        self.feature_list = feature_list or SELECTED_FEATURES
        self.model_params = model_params or self._get_default_params()
        self.model = None
        self.feature_importance = None
        self.training_metrics = {}

    def _get_default_params(self) -> Dict:
        """ê¸°ë³¸ LightGBM íŒŒë¼ë¯¸í„°"""
        return {
            'objective': 'binary',
            'metric': 'binary_logloss',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1,
            'random_state': 42,
            'n_estimators': 100,
            'max_depth': 6,
            'min_child_samples': 20,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1
        }

    def load_data(self,
                  market: str = "KR",
                  years: List[int] = [2018, 2019, 2020],
                  max_tickers: int = 100,
                  feature_set: str = "v2",
                  label_horizon: int = 1,
                  label_thresh: float = 0.05) -> Tuple[pd.DataFrame, pd.Series]:
        """
        í•™ìŠµ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬

        Args:
            market: ì‹œì¥ ì½”ë“œ
            years: í•™ìŠµ ì—°ë„
            max_tickers: ìµœëŒ€ í‹°ì»¤ ìˆ˜
            feature_set: feature set
            label_horizon: ë¼ë²¨ horizon
            label_thresh: ë¼ë²¨ threshold

        Returns:
            X: feature ë°ì´í„°í”„ë ˆì„
            y: target ì‹œë¦¬ì¦ˆ (0: ìƒìŠ¹, 1: í•˜ë½)
        """
        print(f"ğŸ“Š Loading data for {market} market, years {years}...")

        # ë°ì´í„° ë¡œë“œ
        df = build_dataset(
            years=years,
            market=market,
            exchanges=None,
            tickers=None,
            max_tickers=max_tickers,
            start=None,
            end=None,
            feature_set=feature_set,
            label_horizon=label_horizon,
            label_task="classification",
            label_thresh=label_thresh,
            select_cols=None,
            drop_na_rows=True,
            verbose=False,
        )

        print(f"âœ… Loaded {len(df)} samples, {len(df.columns)} columns")

        # ì´ë²¤íŠ¸ ë°ì´í„°ë§Œ í•„í„°ë§ (label_1d_clsê°€ 0ì´ ì•„ë‹Œ ê²½ìš°)
        event_df = df.filter(pl.col("label_1d_cls") != 0)
        print(f"âœ… Filtered to {len(event_df)} directional events")

        if len(event_df) < 1000:
            print(f"âš ï¸ Warning: Only {len(event_df)} samples available. Consider using more data.")

        # Featureì™€ Target ë¶„ë¦¬
        available_features = [f for f in self.feature_list if f in event_df.columns]
        missing_features = [f for f in self.feature_list if f not in event_df.columns]

        if missing_features:
            print(f"âš ï¸ Missing features: {missing_features}")
            print(f"ğŸ“Š Using {len(available_features)} available features: {available_features}")

        # pandasë¡œ ë³€í™˜
        feature_df = event_df.select(available_features).to_pandas()
        target_series = event_df.select("label_1d_cls").to_pandas()["label_1d_cls"]

        # Target ë³€í™˜: -1, 1 -> 0, 1
        y = ((target_series + 1) // 2).astype(int)

        print(f"ğŸ¯ Target distribution: {y.value_counts().to_dict()}")
        print(f"ğŸ“Š Features shape: {feature_df.shape}")

        return feature_df, y

    def train(self,
              X: pd.DataFrame,
              y: pd.Series,
              test_size: float = 0.2,
              use_cv: bool = True,
              cv_folds: int = 5) -> Dict:
        """
        ëª¨ë¸ í•™ìŠµ

        Args:
            X: feature ë°ì´í„°
            y: target ë°ì´í„°
            test_size: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
            use_cv: êµì°¨ê²€ì¦ ì‚¬ìš© ì—¬ë¶€
            cv_folds: êµì°¨ê²€ì¦ fold ìˆ˜

        Returns:
            í•™ìŠµ ê²°ê³¼ ë©”íŠ¸ë¦­
        """
        print("ğŸš€ Training Direction Classifier...")

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )

        print(f"ğŸ“Š Train set: {X_train.shape}, Test set: {X_test.shape}")

        # LightGBM ë°ì´í„°ì…‹ ìƒì„±
        train_data = lgb.Dataset(X_train, label=y_train)
        test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)

        # ëª¨ë¸ í•™ìŠµ
        self.model = lgb.train(
            self.model_params,
            train_data,
            valid_sets=[train_data, test_data],
            valid_names=['train', 'valid'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=20),
                lgb.log_evaluation(period=10)
            ]
        )

        # ì˜ˆì¸¡
        y_pred_proba = self.model.predict(X_test)
        y_pred = (y_pred_proba > 0.5).astype(int)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1_score': f1_score(y_test, y_pred, zero_division=0),
            'roc_auc': roc_auc_score(y_test, y_pred_proba)
        }

        # êµì°¨ê²€ì¦ (ì˜µì…˜)
        if use_cv:
            cv_scores = cross_val_score(
                lgb.LGBMClassifier(**self.model_params),
                X, y, cv=cv_folds, scoring='accuracy'
            )
            metrics['cv_accuracy_mean'] = cv_scores.mean()
            metrics['cv_accuracy_std'] = cv_scores.std()

        # Feature Importance ì €ì¥
        self.feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': self.model.feature_importance(importance_type='gain')
        }).sort_values('importance', ascending=False)

        self.training_metrics = metrics

        print("âœ… Training completed!")
        print(f"ğŸ¯ Test Accuracy: {metrics['accuracy']:.4f}")
        print(f"ğŸ¯ Test ROC-AUC: {metrics['roc_auc']:.4f}")

        return metrics

    def predict(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """
        ì˜ˆì¸¡ ìˆ˜í–‰

        Args:
            X: feature ë°ì´í„°

        Returns:
            y_pred: ì˜ˆì¸¡ í´ë˜ìŠ¤ (0, 1)
            y_pred_proba: ì˜ˆì¸¡ í™•ë¥ 
        """
        if self.model is None:
            raise ValueError("Model not trained yet. Call train() first.")

        y_pred_proba = self.model.predict(X)
        y_pred = (y_pred_proba > 0.5).astype(int)

        return y_pred, y_pred_proba

    def evaluate(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """
        ëª¨ë¸ í‰ê°€

        Args:
            X: feature ë°ì´í„°
            y: ì‹¤ì œ target

        Returns:
            í‰ê°€ ë©”íŠ¸ë¦­
        """
        y_pred, y_pred_proba = self.predict(X)

        return {
            'accuracy': accuracy_score(y, y_pred),
            'precision': precision_score(y, y_pred, zero_division=0),
            'recall': recall_score(y, y_pred, zero_division=0),
            'f1_score': f1_score(y, y_pred, zero_division=0),
            'roc_auc': roc_auc_score(y, y_pred_proba),
            'confusion_matrix': confusion_matrix(y, y_pred),
            'classification_report': classification_report(y, y_pred, zero_division=0)
        }

    def plot_feature_importance(self, save_path: Optional[str] = None, top_n: int = 20):
        """Feature Importance ì‹œê°í™”"""
        if self.feature_importance is None:
            raise ValueError("Model not trained yet or no feature importance available.")

        plt.figure(figsize=(12, 8))

        top_features = self.feature_importance.head(top_n)
        bars = plt.barh(range(len(top_features)), top_features['importance'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('Feature Importance (Gain)')
        plt.title(f'Direction Classifier - Top {top_n} Feature Importance', fontweight='bold')
        plt.grid(True, alpha=0.3, axis='x')

        # ê°’ ë ˆì´ë¸” ì¶”ê°€
        for i, v in enumerate(top_features['importance']):
            plt.text(v + max(top_features['importance']) * 0.01, i,
                    '.3f', va='center', fontsize=9)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=160, bbox_inches='tight')
            print(f"ğŸ’¾ Feature importance plot saved to {save_path}")

        plt.show()

    def plot_confusion_matrix(self, X: pd.DataFrame, y: pd.Series, save_path: Optional[str] = None):
        """Confusion Matrix ì‹œê°í™”"""
        y_pred, _ = self.predict(X)
        cm = confusion_matrix(y, y_pred)

        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=['Down (-1)', 'Up (+1)'],
                   yticklabels=['Down (-1)', 'Up (+1)'])
        plt.title('Direction Classifier - Confusion Matrix', fontweight='bold')
        plt.ylabel('True Direction')
        plt.xlabel('Predicted Direction')
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=160, bbox_inches='tight')
            print(f"ğŸ’¾ Confusion matrix saved to {save_path}")

        plt.show()

    def save_model(self, filepath: str):
        """ëª¨ë¸ ì €ì¥"""
        if self.model is None:
            raise ValueError("No model to save. Train the model first.")

        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        # LightGBM ëª¨ë¸ ì €ì¥
        self.model.save_model(filepath)

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'feature_list': self.feature_list,
            'model_params': self.model_params,
            'feature_importance': self.feature_importance.to_dict() if self.feature_importance is not None else None,
            'training_metrics': self.training_metrics
        }

        metadata_path = filepath.replace('.txt', '_metadata.pkl')
        with open(metadata_path, 'wb') as f:
            pickle.dump(metadata, f)

        print(f"ğŸ’¾ Model saved to {filepath}")
        print(f"ğŸ’¾ Metadata saved to {metadata_path}")

    def load_model(self, filepath: str):
        """ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"Model file not found: {filepath}")

        # LightGBM ëª¨ë¸ ë¡œë“œ
        self.model = lgb.Booster(model_file=filepath)

        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        metadata_path = filepath.replace('.txt', '_metadata.pkl')
        if os.path.exists(metadata_path):
            with open(metadata_path, 'rb') as f:
                metadata = pickle.load(f)

            self.feature_list = metadata.get('feature_list', [])
            self.model_params = metadata.get('model_params', {})
            self.feature_importance = pd.DataFrame(metadata.get('feature_importance', {}))
            self.training_metrics = metadata.get('training_metrics', {})

        print(f"ğŸ“‚ Model loaded from {filepath}")

    def get_feature_correlation(self, X: pd.DataFrame, save_path: Optional[str] = None):
        """Feature ê°„ ìƒê´€ê´€ê³„ ë¶„ì„"""
        corr_matrix = X.corr()

        plt.figure(figsize=(14, 12))
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,
                   square=True, linewidths=0.5, cbar_kws={"shrink": 0.8},
                   fmt='.2f', annot_kws={'size': 8})
        plt.title('Direction Classifier Features - Correlation Matrix', fontweight='bold')
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=160, bbox_inches='tight')
            print(f"ğŸ’¾ Correlation matrix saved to {save_path}")

        plt.show()

        return corr_matrix

def create_direction_classifier_model(market: str = "KR",
                                    years: List[int] = [2018, 2019, 2020],
                                    save_model: bool = True,
                                    model_dir: str = "models/saved") -> DirectionClassifierLGBM:
    """
    ë°©í–¥ ë¶„ë¥˜ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ

    Args:
        market: ì‹œì¥ ì½”ë“œ
        years: í•™ìŠµ ì—°ë„
        save_model: ëª¨ë¸ ì €ì¥ ì—¬ë¶€
        model_dir: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬

    Returns:
        í•™ìŠµëœ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
    """
    print("ğŸ¯ Creating Direction Classifier Model...")
    print(f"ğŸ“Š Selected Features ({len(SELECTED_FEATURES)}):")
    for i, feature in enumerate(SELECTED_FEATURES, 1):
        print(f"  {i}. {feature}")
    print()

    # ëª¨ë¸ ìƒì„±
    model = DirectionClassifierLGBM()

    # ë°ì´í„° ë¡œë“œ
    X, y = model.load_data(market=market, years=years)

    # Feature ìƒê´€ê´€ê³„ í™•ì¸
    print("ğŸ” Checking feature correlations...")
    corr_matrix = model.get_feature_correlation(X)

    # ìƒê´€ê´€ê³„ê°€ 0.8 ì´ìƒì¸ feature ìŒ ì¶œë ¥
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if abs(corr_matrix.iloc[i, j]) >= 0.8:
                high_corr_pairs.append((
                    corr_matrix.columns[i],
                    corr_matrix.columns[j],
                    corr_matrix.iloc[i, j]
                ))

    if high_corr_pairs:
        print("âš ï¸ High correlation pairs (|corr| >= 0.8):")
        for feat1, feat2, corr in high_corr_pairs:
            print(f"  {feat1} - {feat2}: {corr:.3f}")
        print()
    else:
        print("âœ… No high correlation pairs found!")
        print()

    # ëª¨ë¸ í•™ìŠµ
    metrics = model.train(X, y)

    # ê²°ê³¼ ì¶œë ¥
    print("ğŸ“Š Model Performance:")
    for metric, value in metrics.items():
        if isinstance(value, float):
            print(f"  {metric}: {value:.4f}")
        else:
            print(f"  {metric}: {value}")
    print()

    # Feature Importance ì¶œë ¥
    if model.feature_importance is not None:
        print("ğŸ¯ Top 10 Feature Importance:")
        top_10 = model.feature_importance.head(10)
        for i, row in top_10.iterrows():
            print(f"  {row['feature']}: {row['importance']:.4f}")
        print()

    # ëª¨ë¸ ì €ì¥
    if save_model:
        os.makedirs(model_dir, exist_ok=True)
        model_path = os.path.join(model_dir, f"direction_classifier_{market}_{'_'.join(map(str, years))}.txt")
        model.save_model(model_path)

    return model

if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    model = create_direction_classifier_model(
        market="KR",
        years=[2018, 2019, 2020],
        save_model=True
    )

    print("âœ… Direction Classifier Model created successfully!")
    print(f"ğŸ¯ Features used: {len(SELECTED_FEATURES)}")
    print(f"ğŸ† Best accuracy: {model.training_metrics.get('accuracy', 'N/A')}")
    print(f"ğŸ† Best ROC-AUC: {model.training_metrics.get('roc_auc', 'N/A')}")
