from __future__ import annotations

"""

ì¢…í•© ê²°ë¡ 

featureë³„ ì´ë²¤íŠ¸ ë§ì¶œ ì„±ê³µë¥ 
rel_range: ë³€ë™í­, 7%
vol/obv/parkinson/gk: ë³€ë™ì„±/ê±°ë˜ëŸ‰ 6%
atr: ë°©í–¥ ì •í™•ë„ëŠ” 50% ì •ë„ì§€ë§Œ ë‹¨ì¼ ì„±ê³µë¥ ì€ ë§¤ìš° ë‚®ìŒ

ë³´í†µì˜ ì˜¤ë¥´ë‚´ë¦¼ ë“± ë¯¸ì•½í•œ ë³€ë™ì„±/ê±°ë˜ëŸ‰ ì¦ê°€ë§Œìœ¼ë¡œëŠ” ì¢‹ì€ ì‹œê·¸ë„ì´ ì•„ë‹ˆì§€ë§Œ extreme zone(>2)ì—ì„œëŠ” ì´ë²¤íŠ¸ì™€ ê·¼ì ‘í•œ ìˆ˜ìµë¥ 
* ê·¹ë‹¨ê°’ë§Œ í•„í„°ë§, ë‹¤ì¤‘ í•„í„°ë§(ë‹¨ìˆœíˆ í•œ feature ê°’ì— ëŒ€í•œ ê¸°ì¤€ì´ ì•„ë‹˜)
* ë”°ë¼ì„œ ì¼ë‹¨ event detectection -> ë°©í–¥ ë¶„ë¥˜ê¸° ì¶”ê°€
* ì´í›„ í•´ë‹¹ í”¼ì³ë“¤ë¡œ ì˜ˆì¸¡ ì„±ëŠ¥ ë†’íˆê¸°

ì •ë¦¬í•˜ìë©´, rel_range, vol, obv, atrì€ "ë³€ë™ì„± íƒì§€"ì— ìœ ì˜ë¯¸, ê·¸ëŸ¬ë‚˜ ì •ë§ +ì¸ì§€ -ì¸ì§€ íƒì§€ì—ëŠ” ë¬¸ì œê°€ ìˆìŒ.
ë”°ë¼ì„œ ë°©í–¥ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” featureë“¤ì„ ì„ ë°œí•´ì•¼í•¨

ê²½í—˜ìƒ One-Shotìœ¼ë¡œ +, -, else 3class ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“¤ê³  ì„±ê³µë„ í•´ë´¤ìœ¼ë‚˜ í´ë˜ìŠ¤ë¶ˆê· í˜•+ì—°ì†ì‹¤íŒ¨ë¡œ "ì¢†ëœ ì ì´ ìˆìŒ"

ë”°ë¼ì„œ, Event Detector + Direction Classifier, No-trade zone í™•ë³´ í•„ìš”

"""

import os
from pathlib import Path
from typing import Iterable, List, Tuple

import polars as pl
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from matplotlib.patches import Rectangle

from data.dataset_builder import build_dataset

BASE_COLS = {
    "date","ticker","market","exchange","currency","year",
    "open","high","low","close","adj_close","volume","turnover",
}

def _ensure_outdir(path: Path) -> Path:
    path.mkdir(parents=True, exist_ok=True)
    return path

def _pick_feature_cols(df: pl.DataFrame, target_col: str) -> List[str]:
    cols = []
    for c, dt in df.schema.items():
        if c in BASE_COLS:
            continue
        if c == target_col or c.startswith("label_") or c.startswith("futret_"):
            continue
        if dt in (pl.Float32, pl.Float64, pl.Int32, pl.Int64, pl.UInt32, pl.UInt64):
            cols.append(c)
    return cols

def compute_event_prediction_performance(df: pl.DataFrame, feature_cols: List[str], label_col: str = "label_1d_cls") -> Tuple[pl.DataFrame, pl.DataFrame]:
    """
    ì´ë²¤íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë‚ ì§œë³„ë¡œ ê³„ì‚°:
    ê° ë‚ ì§œì—ì„œ í”¼ì²˜ ê°’ì´ ë†’ì€/ë‚®ì€ ì£¼ì‹ë“¤ì´ ì‹¤ì œ ì´ë²¤íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•˜ëŠ”ì§€ ì¸¡ì •
    
    ì„±ëŠ¥ ì§€í‘œ:
    - Event Prediction Score: í”¼ì²˜ ìƒìœ„ 20% vs í•˜ìœ„ 20%ì˜ ì´ë²¤íŠ¸ ë°œìƒë¥  ì°¨ì´
    - Directional Accuracy: +ì´ë²¤íŠ¸ vs -ì´ë²¤íŠ¸ ë°©í–¥ ì˜ˆì¸¡ ì •í™•ë„
    
    ë°˜í™˜:
      - perf_long: columns=[date, feature, event_pred_score, direction_accuracy]
      - perf_summary: per-feature summary(mean, std, success_rate)
    """
    performance_results = []
    
    # ê° ë‚ ì§œë³„ë¡œ ì´ë²¤íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥ ê³„ì‚°
    for date in df["date"].unique().sort():
        date_df = df.filter(pl.col("date") == date)
        
        if len(date_df) < 10:  # ìµœì†Œ 10ê°œ ì£¼ì‹ í•„ìš”
            continue
            
        date_results = {"date": date}
        
        for feature in feature_cols:
            feature_data = date_df.select([feature, label_col]).to_pandas()
            feature_data = feature_data.dropna()
            
            if len(feature_data) < 10:
                continue
                
            # í”¼ì²˜ ê°’ ê¸°ì¤€ ìƒìœ„/í•˜ìœ„ 20% ë¶„í• 
            top_20_threshold = feature_data[feature].quantile(0.8)
            bottom_20_threshold = feature_data[feature].quantile(0.2)
            
            top_20_mask = feature_data[feature] >= top_20_threshold
            bottom_20_mask = feature_data[feature] <= bottom_20_threshold
            
            # ì´ë²¤íŠ¸ ë°œìƒë¥  ê³„ì‚° (0ì´ ì•„ë‹Œ ë¼ë²¨ = ì´ë²¤íŠ¸)
            top_20_event_rate = (feature_data.loc[top_20_mask, label_col] != 0).mean()
            bottom_20_event_rate = (feature_data.loc[bottom_20_mask, label_col] != 0).mean()
            
            # Event Prediction Score: ìƒìœ„ 20% vs í•˜ìœ„ 20%ì˜ ì´ë²¤íŠ¸ ë°œìƒë¥  ì°¨ì´
            event_pred_score = top_20_event_rate - bottom_20_event_rate
            
            # Directional Accuracy: +ì´ë²¤íŠ¸ vs -ì´ë²¤íŠ¸ ë°©í–¥ ì˜ˆì¸¡
            pos_events = feature_data[feature_data[label_col] == 1]  # +5% ì´ìƒ
            neg_events = feature_data[feature_data[label_col] == -1]  # -5% ì´í•˜
            
            direction_accuracy = 0.5  # ê¸°ë³¸ê°’
            if len(pos_events) > 0 and len(neg_events) > 0:
                pos_feature_mean = pos_events[feature].mean()
                neg_feature_mean = neg_events[feature].mean()
                
                # ì–‘ì˜ ì´ë²¤íŠ¸ì—ì„œ í”¼ì²˜ê°€ ë” ë†’ìœ¼ë©´ ë°©í–¥ ì˜ˆì¸¡ ì„±ê³µ
                if pos_feature_mean > neg_feature_mean:
                    direction_accuracy = 1.0
                else:
                    direction_accuracy = 0.0
            
            date_results[f"{feature}_event_pred_score"] = event_pred_score
            date_results[f"{feature}_direction_accuracy"] = direction_accuracy
        
        performance_results.append(date_results)
    
    # DataFrameìœ¼ë¡œ ë³€í™˜
    perf_df = pl.DataFrame(performance_results)
    
    # Long formatìœ¼ë¡œ ë³€í™˜
    event_score_cols = [c for c in perf_df.columns if c.endswith("_event_pred_score")]
    direction_cols = [c for c in perf_df.columns if c.endswith("_direction_accuracy")]
    
    # Event prediction scoresë¥¼ long formatìœ¼ë¡œ
    perf_long_list = []
    for score_col, dir_col in zip(event_score_cols, direction_cols):
        feature_name = score_col.replace("_event_pred_score", "")
        
        temp_df = perf_df.select([
            "date", 
            score_col, 
            dir_col
        ]).rename({
            score_col: "event_pred_score",
            dir_col: "direction_accuracy"
        }).with_columns([
            pl.lit(feature_name).alias("feature")
        ]).select(["date", "feature", "event_pred_score", "direction_accuracy"])
        
        perf_long_list.append(temp_df)
    
    if not perf_long_list:
        # ë¹ˆ DataFrame ë°˜í™˜
        perf_long = pl.DataFrame({
            "date": [], "feature": [], "event_pred_score": [], "direction_accuracy": []
        })
        perf_summary = pl.DataFrame({
            "feature": [], "n_days": [], "event_pred_mean": [], "direction_acc_mean": [], "success_rate": []
        })
        return perf_long, perf_summary
    
    perf_long = pl.concat(perf_long_list).drop_nulls()
    
    # ë¡¤ë§ í†µê³„ ì¶”ê°€
    perf_long = (
        perf_long.sort(["feature", "date"])
               .with_columns([
                    pl.col("event_pred_score").rolling_mean(30).over("feature").alias("event_pred_ma30"),
                    pl.col("direction_accuracy").rolling_mean(30).over("feature").alias("direction_acc_ma30"),
               ])
    )
    
    # ìš”ì•½ í†µê³„
    perf_summary = (
        perf_long.group_by("feature")
               .agg([
                   pl.len().alias("n_days"),
                    pl.col("event_pred_score").mean().alias("event_pred_mean"),
                    pl.col("direction_accuracy").mean().alias("direction_acc_mean"),
                    (pl.col("event_pred_score") > 0).mean().alias("positive_pred_rate"),
               ])
               .with_columns([
                    # ì„±ê³µë¥  = ì´ë²¤íŠ¸ ì˜ˆì¸¡ë ¥ + ë°©í–¥ ì •í™•ë„ì˜ ì¡°í•©
                    (pl.col("event_pred_mean").abs() * pl.col("direction_acc_mean")).alias("success_rate")
               ])
                .sort("success_rate", descending=True)
    )
    
    return perf_long, perf_summary

def event_filter(df: pl.DataFrame, target_col: str = "futret_1", thresh: float = 0.05) -> pl.DataFrame:
    return df.filter(pl.col(target_col).abs() >= thresh)

def plot_scatter_overlay(df_all: pl.DataFrame, df_event: pl.DataFrame, feature: str, label_col: str, out_path: Path, success_rate: float = None):
    """ì „ì²´ ë°ì´í„°ì™€ ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ ê²¹ì³ì„œ ë³´ì—¬ì£¼ëŠ” ì‚°ì ë„"""
    # futret_1ì„ Yì¶•ìœ¼ë¡œ ì‚¬ìš© (ì‹œê°í™”ìš©)
    futret_col = "futret_1"
    pdf_all = df_all.select(["date","ticker", feature, futret_col]).to_pandas()
    pdf_event = df_event.select(["date","ticker", feature, futret_col]).to_pandas()
    
    plt.figure(figsize=(10, 6))
    
    # ì „ì²´ ë°ì´í„° (ì—°í•œ ë°°ê²½)
    sns.scatterplot(data=pdf_all, x=feature, y=futret_col, alpha=0.1, s=8, color='lightblue', label='All data')
    
    # ì´ë²¤íŠ¸ ë°ì´í„° (ê°•ì¡°)
    sns.scatterplot(data=pdf_event, x=feature, y=futret_col, alpha=0.6, s=15, color='red', label='Event (|Î”|â‰¥5%)')
    
    # íšŒê·€ì„ ë“¤
    sns.regplot(data=pdf_all, x=feature, y=futret_col, scatter=False, color="blue", lowess=True, 
                line_kws={"lw": 2, "alpha": 0.7}, label='All trend')
    sns.regplot(data=pdf_event, x=feature, y=futret_col, scatter=False, color="red", lowess=True, 
                line_kws={"lw": 2.5}, label='Event trend')
    
    # ì´ë²¤íŠ¸ ê²½ê³„ì„  í‘œì‹œ
    plt.axhline(y=0.05, color='orange', linestyle='--', alpha=0.7, linewidth=1)
    plt.axhline(y=-0.05, color='orange', linestyle='--', alpha=0.7, linewidth=1)
    plt.fill_between(plt.xlim(), -0.05, 0.05, alpha=0.1, color='gray', label='Non-event zone')
    
    # ì œëª©ê³¼ ë ˆì´ë¸”
    title = f"{feature} vs {futret_col}"
    if success_rate is not None:
        title += f" (Success Rate: {success_rate:.3f})"
    plt.title(title, fontsize=14, fontweight='bold')
    plt.xlabel(feature, fontsize=12)
    plt.ylabel(futret_col, fontsize=12)
    plt.legend(loc='best', framealpha=0.9)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(out_path, dpi=160, bbox_inches='tight')
    plt.close()

def plot_scatter_comparison_matrix(df_all: pl.DataFrame, df_event: pl.DataFrame, features: List[str], 
                                 target_col: str, out_path: Path, perf_summary: pl.DataFrame):
    """ìƒìœ„ ì§€í‘œë“¤ì„ í•œ ë²ˆì— ë¹„êµí•  ìˆ˜ ìˆëŠ” subplot ë§¤íŠ¸ë¦­ìŠ¤"""
    n_features = len(features)
    n_cols = 3
    n_rows = (n_features + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
    if n_rows == 1:
        axes = axes.reshape(1, -1)
    
    # ì„±ëŠ¥ ê°’ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    perf_dict = {row['feature']: row['success_rate'] for row in perf_summary.to_dicts()}
    
    for idx, feature in enumerate(features):
        row = idx // n_cols
        col = idx % n_cols
        ax = axes[row, col]
        
        # futret_1ì„ Yì¶•ìœ¼ë¡œ ì‚¬ìš©
        futret_col = "futret_1"
        pdf_all = df_all.select([feature, futret_col]).to_pandas()
        pdf_event = df_event.select([feature, futret_col]).to_pandas()
        
        # ì „ì²´ ë°ì´í„°
        ax.scatter(pdf_all[feature], pdf_all[futret_col], alpha=0.1, s=4, color='lightblue')
        # ì´ë²¤íŠ¸ ë°ì´í„°
        ax.scatter(pdf_event[feature], pdf_event[futret_col], alpha=0.6, s=8, color='red')
        
        # íšŒê·€ì„ 
        sns.regplot(data=pdf_event, x=feature, y=futret_col, scatter=False, color="red", 
                   lowess=True, line_kws={"lw": 2}, ax=ax)
        
        # ì´ë²¤íŠ¸ ê²½ê³„ì„ 
        ax.axhline(y=0.05, color='orange', linestyle='--', alpha=0.5)
        ax.axhline(y=-0.05, color='orange', linestyle='--', alpha=0.5)
        
        # ì œëª©
        perf_val = perf_dict.get(feature, 0)
        ax.set_title(f"{feature}\n(Success: {perf_val:.3f})", fontsize=10, fontweight='bold')
        ax.set_xlabel(feature, fontsize=9)
        ax.set_ylabel(futret_col, fontsize=9)
        ax.grid(True, alpha=0.3)
    
    # ë¹ˆ subplot ì œê±°
    for idx in range(n_features, n_rows * n_cols):
        row = idx // n_cols
        col = idx % n_cols
        fig.delaxes(axes[row, col])
    
    plt.suptitle(f"Top {n_features} Features Comparison", fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(out_path, dpi=160, bbox_inches='tight')
    plt.close()

def plot_performance_timeseries(perf_long: pl.DataFrame, top_features: List[str], out_path: Path):
    """ìƒìœ„ ì§€í‘œë“¤ì˜ ì´ë²¤íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥ ì‹œê³„ì—´ ì°¨íŠ¸"""
    perf_data = perf_long.filter(pl.col("feature").is_in(top_features)).to_pandas()
    
    plt.figure(figsize=(15, 10))
    
    # ê° ì§€í‘œë³„ë¡œ ì„œë¸Œí”Œë¡¯ ìƒì„±
    n_features = len(top_features)
    n_cols = 2
    n_rows = (n_features + n_cols - 1) // n_cols
    
    for idx, feature in enumerate(top_features):
        plt.subplot(n_rows, n_cols, idx + 1)
        
        feature_data = perf_data[perf_data['feature'] == feature]
        feature_data['date'] = pd.to_datetime(feature_data['date'])
        feature_data = feature_data.sort_values('date')
        
        # ì´ë²¤íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥ ì‹œê³„ì—´
        plt.plot(feature_data['date'], feature_data['event_pred_score'], alpha=0.6, color='blue', linewidth=1, label='Event Pred Score')
        # ë°©í–¥ ì •í™•ë„ ì‹œê³„ì—´
        plt.plot(feature_data['date'], feature_data['direction_accuracy'], alpha=0.6, color='green', linewidth=1, label='Direction Accuracy')
        
        # 30ì¼ ì´ë™í‰ê· 
        if 'event_pred_ma30' in feature_data.columns:
            plt.plot(feature_data['date'], feature_data['event_pred_ma30'], color='red', linewidth=2, label='30d MA')
        
        # ê¸°ì¤€ì„ ë“¤
        plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)
        plt.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='Random (0.5)')
        
        plt.title(f"{feature} Event Prediction Performance", fontweight='bold')
        plt.ylabel('Performance Score')
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        plt.ylim(-0.1, 1.1)
        
        if idx == 0:
            plt.legend(fontsize=8)
    
    plt.tight_layout()
    plt.savefig(out_path, dpi=160, bbox_inches='tight')
    plt.close()

def plot_event_rate_timeseries(event_rate_data: pl.DataFrame, out_path: Path):
    """ì´ë²¤íŠ¸ ë°œìƒë¥  ì‹œê³„ì—´ ì°¨íŠ¸"""
    pdf = event_rate_data.to_pandas()
    pdf['date'] = pd.to_datetime(pdf['date'])
    pdf = pdf.sort_values('date')
    
    plt.figure(figsize=(15, 6))
    
    # ì´ë²¤íŠ¸ìœ¨ ì‹œê³„ì—´
    plt.plot(pdf['date'], pdf['event_rate'], color='red', linewidth=1.5, alpha=0.8)
    plt.fill_between(pdf['date'], pdf['event_rate'], alpha=0.3, color='red')
    
    # í‰ê· ì„ 
    mean_rate = pdf['event_rate'].mean()
    plt.axhline(y=mean_rate, color='blue', linestyle='--', linewidth=2, 
                label=f'Average: {mean_rate:.3f}')
    
    # ê³ ë³€ë™ì„± êµ¬ê°„ í‘œì‹œ (ìƒìœ„ 10%)
    high_vol_threshold = pdf['event_rate'].quantile(0.9)
    plt.axhline(y=high_vol_threshold, color='orange', linestyle='--', linewidth=2,
                label=f'90th percentile: {high_vol_threshold:.3f}')
    
    plt.title('Event Rate Time Series (Daily % of stocks with |return| â‰¥ 5%)', 
              fontsize=14, fontweight='bold')
    plt.xlabel('Date')
    plt.ylabel('Event Rate')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(out_path, dpi=160, bbox_inches='tight')
    plt.close()

def plot_feature_correlation_heatmap(df: pl.DataFrame, top_features: List[str], out_path: Path):
    """ìƒìœ„ ì§€í‘œë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ"""
    corr_data = df.select(top_features).to_pandas().corr()
    
    plt.figure(figsize=(10, 8))
    
    # ë§ˆìŠ¤í¬ ìƒì„± (ìƒì‚¼ê°í˜• ìˆ¨ê¸°ê¸°)
    mask = np.triu(np.ones_like(corr_data, dtype=bool))
    
    # íˆíŠ¸ë§µ
    sns.heatmap(corr_data, mask=mask, annot=True, cmap='RdBu_r', center=0,
                square=True, linewidths=0.5, cbar_kws={"shrink": 0.8},
                fmt='.3f', annot_kws={'size': 9})
    
    plt.title('Feature Correlation Heatmap (Top Performers)', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(out_path, dpi=160, bbox_inches='tight')
    plt.close()

def plot_performance_summary_bar(perf_summary: pl.DataFrame, out_path: Path):
    """ì§€í‘œë³„ ì´ë²¤íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥ ìš”ì•½ ë°” ì°¨íŠ¸"""
    # ìƒìœ„ 15ê°œ ì§€í‘œë§Œ í‘œì‹œ
    top_data = perf_summary.head(15).to_pandas()
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # Success Rate ë°” ì°¨íŠ¸
    bars1 = ax1.barh(range(len(top_data)), top_data['success_rate'], 
                     color=['green' if x >= 0.6 else 'orange' if x >= 0.4 else 'red' 
                           for x in top_data['success_rate']])
    ax1.set_yticks(range(len(top_data)))
    ax1.set_yticklabels(top_data['feature'], fontsize=10)
    ax1.set_xlabel('Success Rate (Event Pred Ã— Direction Acc)', fontsize=12)
    ax1.set_title('Event Prediction Success Rate', fontsize=14, fontweight='bold')
    ax1.axvline(x=0.6, color='green', linestyle='--', alpha=0.7, label='Good (â‰¥0.6)')
    ax1.axvline(x=0.4, color='orange', linestyle='--', alpha=0.7, label='Fair (â‰¥0.4)')
    ax1.axvline(x=0.25, color='red', linestyle='--', alpha=0.7, label='Random (0.25)')
    ax1.legend()
    ax1.grid(True, alpha=0.3, axis='x')
    
    # ê°’ ë ˆì´ë¸” ì¶”ê°€
    for i, v in enumerate(top_data['success_rate']):
        ax1.text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)
    
    # Direction Accuracy ë°” ì°¨íŠ¸
    bars2 = ax2.barh(range(len(top_data)), top_data['direction_acc_mean'], 
                     color=['darkgreen' if x >= 0.7 else 'darkblue' if x >= 0.6 else 'gray' 
                           for x in top_data['direction_acc_mean']])
    ax2.set_yticks(range(len(top_data)))
    ax2.set_yticklabels(top_data['feature'], fontsize=10)
    ax2.set_xlabel('Direction Accuracy', fontsize=12)
    ax2.set_title('Event Direction Prediction Accuracy', fontsize=14, fontweight='bold')
    ax2.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Random (0.5)')
    ax2.legend()
    ax2.grid(True, alpha=0.3, axis='x')
    
    # ê°’ ë ˆì´ë¸” ì¶”ê°€
    for i, v in enumerate(top_data['direction_acc_mean']):
        ax2.text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)
    
    plt.tight_layout()
    plt.savefig(out_path, dpi=160, bbox_inches='tight')
    plt.close()

def build_train_frame(
    market: str = "KR",
    years: Iterable[int] = (2018, 2019, 2020),
    max_tickers: int = 100,
    feature_set: str = "v2",
    label_horizon: int = 1,
    label_task: str = "classification",
    label_thresh: float = 0.05,
    verbose: bool = True,
) -> pl.DataFrame:
    df = build_dataset(
        years=years,
        market=market,
        exchanges=None,
        tickers=None,
        max_tickers=max_tickers,
        start=None,
        end=None,
        feature_set=feature_set,
        label_horizon=label_horizon,
        label_task=label_task,
        label_thresh=label_thresh,
        select_cols=None,
        drop_na_rows=True,
        verbose=verbose,
    )
    # ë¶„ë¥˜ ë¼ë²¨ê³¼ íšŒê·€ íƒ€ê¹ƒì´ í•¨ê»˜ í•„ìš”í•˜ë‹ˆ horizon=1ì¼ì˜ futret_1ë„ ì¡´ì¬í•´ì•¼ í•¨
    # build_datasetëŠ” always futret_{horizon}ë¥¼ ìƒì„±
    return df

def run_analytics(
    market: str = "KR",
    years_train: Iterable[int] = (2018, 2019, 2020),
    max_tickers: int = 30,
    feature_set: str = "v2",
    label_col: str = "label_1d_cls",
    event_thresh: float = 0.05,
    topk_plots: int = 8,
):
    root = Path(__file__).resolve().parent
    out_dir = _ensure_outdir(root / "outputs" / "M001")
    plots_dir = _ensure_outdir(out_dir / "plots")
    tables_dir = _ensure_outdir(out_dir / "tables")

    # 1) ë°ì´í„°ì…‹ ë¡œë“œ
    df = build_train_frame(
        market=market,
        years=years_train,
        max_tickers=max_tickers,
        feature_set=feature_set,
        label_horizon=1,
        label_task="classification",
        label_thresh=event_thresh,
        verbose=True,
    )

    # 2) í”¼ì²˜ ì»¬ëŸ¼ ì„ íƒ
    feature_cols = _pick_feature_cols(df, target_col=label_col)
    if len(feature_cols) == 0:
        raise RuntimeError("No feature columns detected.")

    # 3) ì´ë²¤íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥ ë¶„ì„
    print(f"[M001] Computing event prediction performance...")
    perf_long, perf_summary = compute_event_prediction_performance(df, feature_cols, label_col=label_col)
    
    # ê²°ê³¼ ì €ì¥
    perf_long.write_csv(str(tables_dir / "event_prediction_performance.csv"))
    perf_summary.write_csv(str(tables_dir / "event_prediction_summary.csv"))
    
    # ì„±ëŠ¥ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    perf_dict = {row['feature']: row['success_rate'] for row in perf_summary.to_dicts()}

    # 4) ì´ë²¤íŠ¸ ë°ì´í„° í•„í„°ë§ (ì‹œê°í™”ìš©)
    ev_df = df.filter(pl.col(label_col) != 0)  # 0ì´ ì•„ë‹Œ ë¼ë²¨ = ì´ë²¤íŠ¸

    # 5) ìµœê³  ì„±ëŠ¥ í”¼ì²˜ë“¤ ì„ ì •
    top_features = (
        perf_summary.filter(pl.col("n_days") >= 30)
                   .sort("success_rate", descending=True)
                  .head(topk_plots)
                  .get_column("feature")
                  .to_list()
    )

    # 6) ì´ë²¤íŠ¸ ë¹„ìœ¨/ìš”ì•½ ì €ì¥
    event_rate_by_date = (
        df.select([
            "date",
            (pl.col(label_col) != 0).cast(pl.Float64).alias("is_event")
        ])
        .group_by("date")
        .agg(pl.col("is_event").mean().alias("event_rate"))
        .sort("date")
    )
    event_rate_by_date.write_csv(str(tables_dir / "event_rate_by_date.csv"))

    # 7) ì¶”ê°€ ì‹œê°í™”ë“¤
    print(f"[M001] Generating time series and summary plots...")
    
    # ì„±ëŠ¥ ì‹œê³„ì—´ ì°¨íŠ¸ (IC ëŒ€ì‹  ì´ë²¤íŠ¸ ì˜ˆì¸¡ ì„±ëŠ¥)
    plot_performance_timeseries(perf_long, top_features, plots_dir / "performance_timeseries_top_features.png")
    
    # ì´ë²¤íŠ¸ìœ¨ ì‹œê³„ì—´ ì°¨íŠ¸
    plot_event_rate_timeseries(event_rate_by_date, plots_dir / "event_rate_timeseries.png")
    
    # ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    plot_feature_correlation_heatmap(df, top_features, plots_dir / "feature_correlation_heatmap.png")
    
    # ì„±ëŠ¥ ìš”ì•½ ë°” ì°¨íŠ¸
    plot_performance_summary_bar(perf_summary, plots_dir / "performance_summary_bars.png")

    # 8) ì¶”ê°€ í†µê³„ í…Œì´ë¸” ìƒì„±
    print(f"[M001] Generating additional analysis tables...")
    
    # ê°œë³„ overlay ì‚°ì ë„ (ì „ì²´ + ì´ë²¤íŠ¸ ê²¹ì³ì„œ)
    for f in top_features:
        plot_scatter_overlay(df, ev_df, f, label_col, 
                           plots_dir / f"scatter_overlay_{f}.png", 
                           success_rate=perf_dict.get(f))

    # ìƒìœ„ ì§€í‘œë“¤ ë¹„êµ ë§¤íŠ¸ë¦­ìŠ¤
    plot_scatter_comparison_matrix(df, ev_df, top_features, label_col, 
                                 plots_dir / "comparison_matrix_top_features.png", 
                                 perf_summary)
    
    # ì›”ë³„ ì„±ëŠ¥ ë¶„ì„ì€ ì œê±° (ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨)
    # ì›”ë³„ ì„±ëŠ¥ ë¶„ì„
    monthly_performance = (
        perf_long.with_columns([
            pl.col("date").dt.strftime("%Y-%m").alias("year_month")
        ])
        .group_by(["year_month", "feature"])
        .agg([
            pl.col("event_pred_score").mean().alias("monthly_event_pred_mean"),
            pl.col("direction_accuracy").mean().alias("monthly_direction_acc_mean"),
            pl.len().alias("days_in_month")
        ])
        .with_columns([
            (pl.col("monthly_event_pred_mean").abs() * pl.col("monthly_direction_acc_mean")).alias("monthly_success_rate")
        ])
        .sort(["year_month", "monthly_success_rate"], descending=[False, True])
    )
    monthly_performance.write_csv(str(tables_dir / "monthly_performance.csv"))

    # ê°„ë‹¨ ë¡œê·¸
    print(f"[M001] âœ… Analysis complete!")
    print(f"[M001] Features analyzed: {len(feature_cols)}")
    print(f"[M001] Top features (by Success Rate): {top_features}")
    print(f"[M001] Generated files:")
    print(f"  ğŸ“Š {len(top_features)} overlay scatter plots")
    print(f"  ğŸ“ˆ 1 comparison matrix")
    print(f"  ğŸ“‰ 4 summary/timeseries charts")
    print(f"  ğŸ“‹ 4 analysis tables")
    print(f"[M001] All outputs saved under: {out_dir}")

if __name__ == "__main__":
    # ê¸°ë³¸ ì‹¤í–‰: KR, 2018â€“2020, v2, ìµœëŒ€ 30í‹°ì»¤, ì´ë²¤íŠ¸ ì„ê³„ 5%
    sns.set_context("talk")
    sns.set_style("whitegrid")
    run_analytics(
        market="KR",
        years_train=(2018, 2019, 2020),
        max_tickers=30,
        feature_set="v2",
        label_col="label_1d_cls",
        event_thresh=0.05,
        topk_plots=8,
    )
